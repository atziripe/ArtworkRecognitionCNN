{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae58fe48-c20a-48d0-8799-7414a6c074e1",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f57878-b91c-40c0-8fca-24ef04808d8e",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88361311-6de7-4b17-af48-4f94621c89a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.3.6)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kagglehub) (24.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kagglehub) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->kagglehub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->kagglehub) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opencv-python-headless) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.0-cp312-cp312-macosx_12_0_arm64.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install kagglehub\n",
    "pip install opencv-python-headless\n",
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce5bcd82-0936-4e92-9ad8-cdbf7cf74618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/ikarus777/best-artworks-of-all-time?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.29G/2.29G [00:51<00:00, 47.7MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/atziripe/.cache/kagglehub/datasets/ikarus777/best-artworks-of-all-time/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ikarus777/best-artworks-of-all-time\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6845a039-0914-40f5-a473-1234a2d013e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mCisco Packet Tracer 8.2.2\u001b[m\u001b[m\n",
      "\u001b[34mDesktop\u001b[m\u001b[m\n",
      "\u001b[34mDocuments\u001b[m\u001b[m\n",
      "\u001b[34mDownloads\u001b[m\u001b[m\n",
      "\u001b[34mLibrary\u001b[m\u001b[m\n",
      "\u001b[34mMovies\u001b[m\u001b[m\n",
      "\u001b[34mMusic\u001b[m\u001b[m\n",
      "\u001b[34mPictures\u001b[m\u001b[m\n",
      "\u001b[34mPostman\u001b[m\u001b[m\n",
      "\u001b[34mPostman Agent\u001b[m\u001b[m\n",
      "\u001b[34mPublic\u001b[m\u001b[m\n",
      "\u001b[34mgo\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%bash\n",
    "cd /Users/atziripe/.cache/kagglehub/datasets/ikarus777/best-artworks-of-all-time/versions/1\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f130d79-fa96-48a0-bcdf-6479e12e2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir dataset/\n",
    "mv /Users/atziripe/.cache/kagglehub/datasets/ikarus777/best-artworks-of-all-time/versions/1 dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b74fe55-95a2-45d4-89ab-d4dfbc128c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 528, Height: 640, Channels: 3\n"
     ]
    }
   ],
   "source": [
    "#check size of resized image and resize it if needed for the model\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('dataset/1/resized/resized/Alfred_Sisley_60.jpg')\n",
    "\n",
    "# Get the dimensions of the image\n",
    "height, width, channels = image.shape\n",
    "\n",
    "print(f\"Width: {width}, Height: {height}, Channels: {channels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5cee413-c326-464d-8b13-9c909c12853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 880, Height: 1066, Channels: 3\n"
     ]
    }
   ],
   "source": [
    "#check size of images before resizing \n",
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('dataset/1/images/images/Alfred_Sisley/Alfred_Sisley_60.jpg')\n",
    "\n",
    "# Get the dimensions of the image\n",
    "height, width, channels = image.shape\n",
    "\n",
    "# Print the dimensions\n",
    "print(f\"Width: {width}, Height: {height}, Channels: {channels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "974abf4a-63f7-4a6e-9bdd-b01c02998d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "def resize_images(input_dir, output_dir, target_size=(224, 224)):\n",
    "    for class_name in os.listdir(input_dir):\n",
    "        class_path = os.path.join(input_dir, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            output_class_dir = os.path.join(output_dir, class_name)\n",
    "            os.makedirs(output_class_dir, exist_ok=True)\n",
    "\n",
    "            for img_name in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                try:\n",
    "                    img = Image.open(img_path)\n",
    "                    img = img.resize(target_size)  # Resize image to target size\n",
    "                    img.save(os.path.join(output_class_dir, img_name))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "# Resize images in the dataset\n",
    "resize_images(\"dataset/1/images/images/\", \"resized_dataset\", target_size=(224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9304a356-0889-4cd8-ba07-8e73f61d996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(input_dir, output_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    for class_name in os.listdir(input_dir):\n",
    "        class_path = os.path.join(input_dir, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            # List all image paths\n",
    "            images = [os.path.join(class_path, img) for img in os.listdir(class_path) if img.endswith(('.jpg', '.png'))]\n",
    "\n",
    "            # Split into train, validation, and test sets\n",
    "            train, temp = train_test_split(images, test_size=(1 - train_ratio), random_state=42)\n",
    "            val, test = train_test_split(temp, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=42)\n",
    "\n",
    "            # Create output directories and move files\n",
    "            for split_name, split_data in zip(['train', 'validation', 'test'], [train, val, test]):\n",
    "                split_dir = os.path.join(output_dir, split_name, class_name)\n",
    "                os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "                for img_path in split_data:\n",
    "                    shutil.copy(img_path, split_dir)\n",
    "\n",
    "# Split the resized dataset\n",
    "split_dataset(\"resized_dataset\", \"final_dataset\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
